library(lme4)
library(MuMIn)
#define the function for overdispersion test
overdisp_fun <- function(model) {
rdf <- df.residual(model)
rp <- residuals(model,type="pearson")
Pearson.chisq <- sum(rp^2)
prat <- Pearson.chisq/rdf
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}
#load data
data = read.csv("c-fos.csv")
options(na.action = "na.fail")
#set data as nominal type
data$Time <- as.factor(data$Time)
data$Sham <- as.factor(data$Sham)
data$Ipsi <- as.factor(data$Ipsi)
data$Distance2 <- as.factor(data$Distance2) #distance2 is nominal data 1,2,3,4,5
#distance1 is re-formed value 0,1,2, labeing the relative distance from small to large
#so distance1 is not redefined as nominal type, data$Distance1 <- as.factor(data$Distance1)
data$AnimalNo <- as.factor(data$AnimalNo)
#split data for 90min, 24hrs, and 48hrs
time1 <- as.data.frame(data[data$Time=="1",])
time2 <- as.data.frame(data[data$Time=="2",])
time3 <- as.data.frame(data[data$Time=="3",])
mod1 = glm(Counting ~ Sham*Ipsi*Distance1, family=poisson,data = time1)
mod2 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo/Distance1), family=poisson,data = time1)
mod3 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1+Distance1|AnimalNo), family=poisson,data = time1)
mod4 = glmer(Counting ~ Sham*Ipsi + (1|AnimalNo) + (1|Distance1), family=poisson,data = time1)
mod5 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), family=poisson,data = time1)
#rank all the candidate models by AIC values
AIC(mod1,mod2,mod5) #mod3 and mod4 is problematic and excluded
#mod2 is selected with the optimal random effects structure
#so mod2 is used as the global model for dredge selection
dd2 <- dredge(mod2)
b2 <- get.models(dd2, 6)[[1]] #get the best-fit model #test for the top 6 models
overdisp_fun(b2) #test the overdispersion of the best-fit model
#the b2 model showed overdispersion (with value >2)
#re-tunning of the model by assuming a negative binomial distribution
mod2 = glmer.nb(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo/Distance1),data = time1)
mod2 = glmer.nb(Counting ~ Sham*Ipsi+Distance1 + (1|AnimalNo/Distance1),data = time1)
mod2 = glmer.nb(Counting ~ Sham*Ipsi+Distance1 + (1|AnimalNo),data = time1)
mod2 = glmer.nb(Counting ~ Sham*Ipsi + (1|Distance1),data = time1)
#remove the group factor to solve the singular problem
library(MASS)
mod2 = glm.nb(Counting ~ Sham*Ipsi*Distance1,data = time1)
overdisp_fun(mod2) #great!
plot(mod2)#looks good
summary(mod2) #sham is significant ***, interaction between sham and ipsi is significant **
mod2 = glm.nb(Counting ~ Sham*Ipsi*Distance1,data = time1)
dd2 <- dredge(mod2)
b2 <- get.models(dd2, 1)[[1]]
overdisp_fun(b2) #great!
library(lme4)
library(MuMIn)
#define the function for overdispersion test
overdisp_fun <- function(model) {
rdf <- df.residual(model)
rp <- residuals(model,type="pearson")
Pearson.chisq <- sum(rp^2)
prat <- Pearson.chisq/rdf
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}
#load data
data = read.csv("c-fos.csv")
options(na.action = "na.fail")
#set data as nominal type
data$Time <- as.factor(data$Time)
data$Sham <- as.factor(data$Sham)
data$Ipsi <- as.factor(data$Ipsi)
data$Distance2 <- as.factor(data$Distance2) #distance2 is nominal data 1,2,3,4,5
#distance1 is re-formed value 0,1,2, labeing the relative distance from small to large
#so distance1 is not redefined as nominal type, data$Distance1 <- as.factor(data$Distance1)
data$AnimalNo <- as.factor(data$AnimalNo)
#split data for 90min, 24hrs, and 48hrs
time1 <- as.data.frame(data[data$Time=="1",])
time2 <- as.data.frame(data[data$Time=="2",])
time3 <- as.data.frame(data[data$Time=="3",])
mod1 = glm(Counting ~ Sham*Ipsi*Distance1, family=poisson,data = time1)
mod2 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo/Distance1), family=poisson,data = time1)
mod3 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1+Distance1|AnimalNo), family=poisson,data = time1)
mod4 = glmer(Counting ~ Sham*Ipsi + (1|AnimalNo) + (1|Distance1), family=poisson,data = time1)
mod5 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), family=poisson,data = time1)
#rank all the candidate models by AIC values
AIC(mod1,mod2,mod5) #mod3 and mod4 is problematic and excluded
#mod2 is selected with the optimal random effects structure
#so mod2 is used as the global model for dredge selection
dd2 <- dredge(mod2)
b2 <- get.models(dd2, 6)[[1]] #get the best-fit model #test for the top 6 models
overdisp_fun(b2) #test the overdispersion of the best-fit model
#the b2 model showed overdispersion (with value >2)
#re-tunning of the model by assuming a negative binomial distribution
mod2 = glmer.nb(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo/Distance1),data = time1)
mod2 = glmer.nb(Counting ~ Sham*Ipsi+Distance1 + (1|AnimalNo),data = time1)
#the b2 model showed overdispersion (with value >2)
#re-tunning of the model by assuming a negative binomial distribution
mod1 = glm.nb(Counting ~ Sham*Ipsi*Distance1,data = time1)
mod2 = glmer.nb(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo/Distance1),data = time1)
mod3 = glmer.nb(Counting ~ Sham*Ipsi*Distance1 + (1+Distance1|AnimalNo), data = time1)
mod4 = glmer.nb(Counting ~ Sham*Ipsi + (1|AnimalNo) + (1|Distance1), data = time1)
mod5 = glmer.nb(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), data = time1)
AIC(mod1,mod2,mod3,mod4,mod5)
overdisp_fun(mod1)
summary(mod1)
dd2 <- dredge(mod1)
b2 <- get.models(dd2, 1)[[1]]
overdisp_fun(b2) #great!
plot(mod2)#looks good
summary(mod2) #sham is significant ***, interaction between sham and ipsi is significant **
#Time2, 24hrs
#select the optimal random effects structure
mod1 = glm(Counting ~ Sham*Ipsi*Distance1, family=poisson,data = time2)
mod2 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo/Distance1), family=poisson,data = time2)
mod3 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1+Distance1|AnimalNo), family=poisson,data = time2)
mod4 = glmer(Counting ~ Sham*Ipsi + (1|AnimalNo) + (1|Distance1), family=poisson,data = time2)
#Time2, 24hrs
#select the optimal random effects structure
mod1 = glm(Counting ~ Sham*Ipsi*Distance1, family=poisson,data = time2)
mod2 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo/Distance1), family=poisson,data = time2)
mod3 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1+Distance1|AnimalNo), family=poisson,data = time2)
mod4 = glmer(Counting ~ Sham*Ipsi + (1|AnimalNo) + (1|Distance1), family=poisson,data = time2)
mod5 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), family=poisson,data = time2)
AIC(mod1,mod2,mod3,mod4,mod5) #mod2 is the best
dd2 <- dredge(mod2)
b2 <- get.models(dd2, 1)[[1]]
overdisp_fun(b2)#top 6 models do not pass the overdispersion test
#re-fit with negative binominal distribution
mod1 = glm.nb(Counting ~ Sham*Ipsi*Distance1,data = time2)
mod2 = glmer.nb(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo/Distance1),data = time2)
mod3 = glmer.nb(Counting ~ Sham*Ipsi*Distance1 + (1+Distance1|AnimalNo),data = time2)
mod4 = glmer.nb(Counting ~ Sham*Ipsi + (1|AnimalNo) + (1|Distance1),data = time2)
mod5 = glmer.nb(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), data = time2)
dd2 <- dredge(mod1)
b2 <- get.models(dd2, 1)[[1]]
overdisp_fun(b2) #no overdispersion
plot(b2) #looks good
summary(b2) # no significance
#Time3, 48hrs
mod1 = glm(Counting ~ Sham*Ipsi*Distance1, family=poisson,data = time3)
mod2 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo/Distance1), family=poisson,data = time3)
mod3 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1+Distance1|AnimalNo), family=poisson,data = time3)
mod4 = glmer(Counting ~ Sham*Ipsi + (1|AnimalNo) + (1|Distance1), family=poisson,data = time3)
mod5 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), family=poisson,data = time3)
AIC(mod1,mod2,mod3,mod4,mod5) #mod5 is the best
dd2 <- dredge(mod2)
dd2 <- dredge(mod1)
b2 <- get.models(dd2, 1)[[1]]
overdisp_fun(b2)#overdispersion for top 6 models
#re-fit with negative binominal distribution
mod1 = glm.nb(Counting ~ Sham*Ipsi*Distance1, data = time3)
mod2 = glmer.nb(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo/Distance1), data = time3)
mod3 = glmer.nb(Counting ~ Sham*Ipsi*Distance1 + (1+Distance1|AnimalNo), data = time3)
mod4 = glmer.nb(Counting ~ Sham*Ipsi + (1|AnimalNo) + (1|Distance1), data = time3)
mod5 = glmer.nb(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), data = time3)
#only mod1 works without singular problem
dd2 <- dredge(mod1)
b2 <- get.models(dd2, 1)[[1]]
overdisp_fun(b2)#overdispersion for top 6 models
plot(b2)
summary(b2)
confint(b2) #not significant
summary(mod1)
dd2
b2 <- get.models(dd2, 3)[[1]]
plot(b2)
summary(b2)
b2 <- get.models(dd2, 6)[[1]]
overdisp_fun(b2)#looks good
plot(b2)
summary(b2)
#only mod1 works without singular problem
summary(mod1)
confint(b2) #not significant
confint(mod1) #not significant
dd2
#only mod1 works without singular problem
dd2 <- dredge(mod1)
summary(mod1)
overdisp_fun(mod1)#looks good
#only mod1 works without singular problem
dd2 <- dredge(mod1)
b2 <- get.models(dd2, 1)[[1]]
overdisp_fun(b2)#looks good
plot(b2)
summary(b2)
confint(b2) #not significant
#only mod1 works without singular problem
overdisp_fun(mod1)#looks good
summary(mod1)
confint(mod1) #not significant
library(lme4)
library(lme4)
library(MuMIn)
#define the function for overdispersion test
overdisp_fun <- function(model) {
rdf <- df.residual(model)
rp <- residuals(model,type="pearson")
Pearson.chisq <- sum(rp^2)
prat <- Pearson.chisq/rdf
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}
#load data
data = read.csv("c-fos.csv")
options(na.action = "na.fail")
#set data as nominal type
data$Time <- as.factor(data$Time)
data$Sham <- as.factor(data$Sham)
data$Ipsi <- as.factor(data$Ipsi)
data$Distance2 <- as.factor(data$Distance2) #distance2 is nominal data 1,2,3,4,5
#distance1 is re-formed value 0,1,2, labeing the relative distance from small to large
#so distance1 is not redefined as nominal type, data$Distance1 <- as.factor(data$Distance1)
data$AnimalNo <- as.factor(data$AnimalNo)
#split data for 90min, 24hrs, and 48hrs
time1 <- as.data.frame(data[data$Time=="1",])
time2 <- as.data.frame(data[data$Time=="2",])
time3 <- as.data.frame(data[data$Time=="3",])
mod1 = glm(Counting ~ Sham*Ipsi*Distance1, family=poisson,data = time1)
library(lme4)
# importin data
data = read.csv("c-fos.csv")
# this is just to check whether evrything is imported correctly
# You need to specifiy certain variables as factors. R will think that they are on a continous
# Or interval scale, since they are registered as numbers. However, things like "sham"
# are clearly your treatment categories and you need to tell this to the program if you dont use
# letters for coding. The same with Random "FACTORS"
str(data)
head(data)
data$Time <- as.factor(data$Time) #
data$Sham <- as.factor(data$Sham) # this needs to be a factpr since it specifies your treatment categories
data$Ipsi <- as.factor(data$Ipsi) #
data$Distance2 <- as.factor(data$Distance2)
data$Distance1 <- as.factor(data$Distance1)
data$AnimalNo <- as.factor(data$AnimalNo)# also here, the animal are not a continous scale but separate identities
time1 <- as.data.frame(data[data$Time=="1",])
time2 <- as.data.frame(data[data$Time=="2",])
time3 <- as.data.frame(data[data$Time=="3",])
model_Time1 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), data = data)
model_Time2 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), data = data)
model_Time3 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), data = data)
library(lattice)
trellis.par.set("background$col" = "white")
# For Time 1 There are some animals which stick out. Based on the scatter, the distance might not have a large impact
xyplot(Counting ~ Distance1 | AnimalNo, pch = 16, cex = 1.3,
par.strip.text = list(cex = 1.5), scales = list(alternating = F), data=time1)
# For Time 2: very similar here
xyplot(Counting ~ Distance1 | AnimalNo, pch = 16, cex = 1.3,
par.strip.text = list(cex = 1.5), scales = list(alternating = F), data=time2)
# For Time 3: here might be a slight distance effect for only animal 22...
xyplot(Counting ~ Distance1 | AnimalNo, pch = 16, cex = 1.3,
par.strip.text = list(cex = 1.5), scales = list(alternating = F), data=time3)
# Time 1: it seems like the interaction model is the best way to describe your data!
m.T1.int <- glmer(Counting ~ Sham * Ipsi + (1|AnimalNo/Distance1), family=poisson, data = time1)
m.T1.add <- glmer(Counting ~ Sham + Ipsi + (1|AnimalNo/Distance1), family=poisson, data = time1)
m.T1.sham <- glmer(Counting ~ Sham + (1|AnimalNo/Distance1), family=poisson, data = time1)
m.T1.ipsi <- glmer(Counting ~ Ipsi + (1|AnimalNo/Distance1), family=poisson, data = time1)
m.T1.null  = glmer(Counting ~ 1 + (1|AnimalNo/Distance1), family=poisson, data = time1)
AIC(m.T1.int,m.T1.add,m.T1.sham,m.T1.ipsi,m.T1.null)#
# Then check whether the model fulfills the assumptions:
# residuals look very good
plot(m.T1.int)
qqnorm(residuals(m.T1.int))
qqline(residuals(m.T1.int))
# Then check whether the model fulfills the assumptions:
# residuals look very good
plot(m.T1.int)
qqnorm(residuals(m.T1.int))
qqline(residuals(m.T1.int))
# in glms, you also have to check for over-dispersion
# Dispersion is a factor by which the variance is
# higher/lower than assumed by the model. A rough estimation of checking this is by dividing
# the residual deviance of the model by the degrees of freedom. The value should be between
# 0.6 and 2 (around 1). This was absolutely not fulfilled here and your model was highly
# ober-dispersed. You can also test this
overdisp_fun <- function(model) {
rdf <- df.residual(model)
rp <- residuals(model,type="pearson")
Pearson.chisq <- sum(rp^2)
prat <- Pearson.chisq/rdf
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}
overdisp_fun(m.T1.int)
# The issue causes some difficulties, but the easiest way to deal with that is to
# assume a negative binomial distribution for your data, which assumes that the dispersion parameter
# can deviate from one.
m.T1.int.b <- glmer.nb(Counting ~ Sham * Ipsi +  (1|AnimalNo/Distance1),  data = time1) # for some reason, this model is over-fitted too. Maybe because the distance has to few levels to be properly estimated.
# I therefore included it as fixed effect, but then got other porblems. So I excluded the AnimalNo and kept Distance to somehow account for the unbalance here
m.T1.int.b <- glmer.nb(Counting ~ Sham * Ipsi +  (1|Distance1),  data = time1)
# I therefore included it as fixed effect, but then got other porblems. So I excluded the AnimalNo and kept Distance to somehow account for the unbalance here
m.T1.int.b <- glmer.nb(Counting ~ Sham * Ipsi +  (1|Distance2),  data = time1)
plot(m.T1.int.b) # now the assumptions look good
qqnorm(residuals(m.T1.int.b))
qqline(residuals(m.T1.int.b))
# then you can extract the effect strengths on link scale (log): you can use these to judge stat significance
summary(m.T1.int.b) #
confint(m.T1.int.b) # these are the 95% CIs. It corresponds to the p values in the summary () output
# You can get the estimated counts (response scale) from your model using the effects package
library(effects)
eff.T1 <- allEffects(m.T1.int.b)# These are the effects on response scale, meaning the counts
plot(eff.T1)# you can also extract the effects and their confidence intervals. Just check what the package has to offer
# Time 2: same here, interaction term is important
m.T2.int <- glmer(Counting ~ Sham * Ipsi + (1|AnimalNo/Distance1), family=poisson, data = time2)
m.T2.add <- glmer(Counting ~ Sham + Ipsi + (1|AnimalNo/Distance1), family=poisson, data = time2)
m.T2.sham <- glmer(Counting ~ Sham + (1|AnimalNo/Distance1), family=poisson, data = time2)
m.T2.ipsi <- glmer(Counting ~ Ipsi + (1|AnimalNo/Distance1), family=poisson, data = time2)
m.T2.null  = glmer(Counting ~ 1 + (1|AnimalNo/Distance1), family=poisson, data = time2)
AIC(m.T2.int,m.T2.add,m.T2.sham,m.T2.ipsi,m.T2.null)# again: the interaction should be kept
overdisp_fun(m.T2.int) # we fit the negative binomial version again
m.T2.int.b <- glmer.nb(Counting ~ Sham * Ipsi +  (1|AnimalNo/Distance1),  data = time2) # same issue as for T1
library(lme4)
# importin data
data = read.csv("psd95.csv")
library(lme4)
# importin data
data = read.csv("c-fos.csv")
# this is just to check whether evrything is imported correctly
# You need to specifiy certain variables as factors. R will think that they are on a continous
# Or interval scale, since they are registered as numbers. However, things like "sham"
# are clearly your treatment categories and you need to tell this to the program if you dont use
# letters for coding. The same with Random "FACTORS"
str(data)
head(data)
data$Time <- as.factor(data$Time) #
data$Sham <- as.factor(data$Sham) # this needs to be a factpr since it specifies your treatment categories
data$Ipsi <- as.factor(data$Ipsi) #
data$Distance2 <- as.factor(data$Distance2)
data$Distance1 <- as.factor(data$Distance1)
data$AnimalNo <- as.factor(data$AnimalNo)# also here, the animal are not a continous scale but separate identities
time1 <- as.data.frame(data[data$Time=="1",])
time2 <- as.data.frame(data[data$Time=="2",])
time3 <- as.data.frame(data[data$Time=="3",])
library(lattice)
trellis.par.set("background$col" = "white")
# For Time 1 There are some animals which stick out. Based on the scatter, the distance might not have a large impact
xyplot(Counting ~ Distance1 | AnimalNo, pch = 16, cex = 1.3,
par.strip.text = list(cex = 1.5), scales = list(alternating = F), data=time1)
# For Time 2: very similar here
xyplot(Counting ~ Distance1 | AnimalNo, pch = 16, cex = 1.3,
par.strip.text = list(cex = 1.5), scales = list(alternating = F), data=time2)
# For Time 3: here might be a slight distance effect for only animal 22...
xyplot(Counting ~ Distance1 | AnimalNo, pch = 16, cex = 1.3,
par.strip.text = list(cex = 1.5), scales = list(alternating = F), data=time3)
# Time 1: it seems like the interaction model is the best way to describe your data!
m.T1.int <- glmer(Counting ~ Sham * Ipsi + (1|AnimalNo/Distance1), family=poisson, data = time1)
m.T1.sham <- glmer(Counting ~ Sham + (1|AnimalNo/Distance1), family=poisson, data = time1)
m.T1.sham <- glmer(Counting ~ Sham + (1|AnimalNo/Distance2), family=poisson, data = time1)
summary
summary(m.T1.sham)
confint(m.T1.sham,level=0.995)
library(lme4)
# importin data
data = read.csv("c-fos.csv")
# this is just to check whether evrything is imported correctly
# You need to specifiy certain variables as factors. R will think that they are on a continous
# Or interval scale, since they are registered as numbers. However, things like "sham"
# are clearly your treatment categories and you need to tell this to the program if you dont use
# letters for coding. The same with Random "FACTORS"
str(data)
head(data)
data$Time <- as.factor(data$Time) #
data$Sham <- as.factor(data$Sham) # this needs to be a factpr since it specifies your treatment categories
data$Ipsi <- as.factor(data$Ipsi) #
data$Distance2 <- as.factor(data$Distance2)
data$Distance1 <- as.factor(data$Distance1)
data$AnimalNo <- as.factor(data$AnimalNo)# also here, the animal are not a continous scale but separate identities
time1 <- as.data.frame(data[data$Time=="1",])
time2 <- as.data.frame(data[data$Time=="2",])
time3 <- as.data.frame(data[data$Time=="3",])
model_Time1 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), data = data)
model_Time2 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), data = data)
model_Time3 = glmer(Counting ~ Sham*Ipsi*Distance1 + (1|AnimalNo), data = data)
library(lattice)
trellis.par.set("background$col" = "white")
# For Time 1 There are some animals which stick out. Based on the scatter, the distance might not have a large impact
xyplot(Counting ~ Distance1 | AnimalNo, pch = 16, cex = 1.3,
par.strip.text = list(cex = 1.5), scales = list(alternating = F), data=time1)
# For Time 2: very similar here
xyplot(Counting ~ Distance1 | AnimalNo, pch = 16, cex = 1.3,
par.strip.text = list(cex = 1.5), scales = list(alternating = F), data=time2)
# For Time 3: here might be a slight distance effect for only animal 22...
xyplot(Counting ~ Distance1 | AnimalNo, pch = 16, cex = 1.3,
par.strip.text = list(cex = 1.5), scales = list(alternating = F), data=time3)
# Time 1: it seems like the interaction model is the best way to describe your data!
m.T1.int <- glmer(Counting ~ Sham * Ipsi + (1|AnimalNo/Distance1), family=poisson, data = time1)
m.T1.add <- glmer(Counting ~ Sham + Ipsi + (1|AnimalNo/Distance1), family=poisson, data = time1)
m.T1.sham <- glmer(Counting ~ Sham + (1|AnimalNo/Distance2), family=poisson, data = time1)
m.T1.ipsi <- glmer(Counting ~ Ipsi + (1|AnimalNo/Distance1), family=poisson, data = time1)
m.T1.null  = glmer(Counting ~ 1 + (1|AnimalNo/Distance1), family=poisson, data = time1)
AIC(m.T1.int,m.T1.add,m.T1.sham,m.T1.ipsi,m.T1.null)#
# Then check whether the model fulfills the assumptions:
# residuals look very good
plot(m.T1.int)
qqnorm(residuals(m.T1.int))
qqline(residuals(m.T1.int))
# in glms, you also have to check for over-dispersion
# Dispersion is a factor by which the variance is
# higher/lower than assumed by the model. A rough estimation of checking this is by dividing
# the residual deviance of the model by the degrees of freedom. The value should be between
# 0.6 and 2 (around 1). This was absolutely not fulfilled here and your model was highly
# ober-dispersed. You can also test this
overdisp_fun <- function(model) {
rdf <- df.residual(model)
rp <- residuals(model,type="pearson")
Pearson.chisq <- sum(rp^2)
prat <- Pearson.chisq/rdf
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}
overdisp_fun(m.T1.int)
# The issue causes some difficulties, but the easiest way to deal with that is to
# assume a negative binomial distribution for your data, which assumes that the dispersion parameter
# can deviate from one.
m.T1.int.b <- glmer.nb(Counting ~ Sham * Ipsi +  (1|AnimalNo/Distance1),  data = time1) # for some reason, this model is over-fitted too. Maybe because the distance has to few levels to be properly estimated.
# I therefore included it as fixed effect, but then got other porblems. So I excluded the AnimalNo and kept Distance to somehow account for the unbalance here
m.T1.int.b <- glmer.nb(Counting ~ Sham * Ipsi +  (1|Distance2),  data = time1)
plot(m.T1.int.b) # now the assumptions look good
qqnorm(residuals(m.T1.int.b))
qqline(residuals(m.T1.int.b))
# then you can extract the effect strengths on link scale (log): you can use these to judge stat significance
summary(m.T1.int.b) #
confint(m.T1.int.b) # these are the 95% CIs. It corresponds to the p values in the summary () output
confint(m.T1.int.b,level=0.999)
confint(m.T1.int.b,level=0.995)
confint(m.T1.int.b,level=0.99)
